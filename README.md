# ClearBI:  AnalÃ­tica de Datos para Business Intelligence

Este proyecto forma parte del Trabajo Fin de Ciclo de Desarrollo de Aplicaciones Multiplataforma. Implementa un sistema completo de integraciÃ³n, almacenamiento y anÃ¡lisis de datos para una empresa ficticia dedicada a la venta de bicicletas y accesorios.

---

## ğŸ“Š DescripciÃ³n

El sistema automatiza la extracciÃ³n, transformaciÃ³n y carga (ETL) de datos provenientes de un ERP, almacena los datos en un **Data Warehouse** en modelo estrella y facilita su anÃ¡lisis mediante la herramienta de visualizaciÃ³n **Metabase**.

---

## ğŸ› ï¸ Arquitectura

- **ERP:** Base de datos operativa con datos normalizados.
- **Data Warehouse BI:** Base de datos desnormalizada para anÃ¡lisis.
- **ETL:** Proceso automatizado de carga de datos.
- **Metabase:** Plataforma para consultas y visualizaciÃ³n de datos.

Los servicios estÃ¡n orquestados mediante **Docker Compose** y organizados en redes internas para mayor seguridad.

[![Texto alternativo](img/arquitectura.png)](img/arquitectura.png)


Los servicios se comunican mediante dos redes internas:
- **etl-net**: ComunicaciÃ³n entre ERP, DWH y ETL
- **bi-net**: ComunicaciÃ³n entre DWH y Metabase

[![Texto alternativo](img/redes.png)](img/redes.png)

---

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ erp/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ init-erp.sh
â”‚   â””â”€â”€ backup.dump
â”œâ”€â”€ bi/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ init-bi.sh
â”‚   â””â”€â”€ schema-bi.sql
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ etl.py
â”‚   â”œâ”€â”€ schema-bi.sql
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ img/
â”‚   â”œâ”€â”€ arquitectura.png
â”‚   â”œâ”€â”€ despliegue.png
â”œâ”€â”€ metabase/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ wait-for-etl.sh
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ Makefile
```

---

## ğŸ“š Requisitos

- Docker & Docker Compose
- Make (opcional, recomendado)
- Python 3.12+ 

---

## ğŸ”§ ConfiguraciÃ³n

1. Copiar el archivo `.env.example` a `.env` y configurar las variables.
2. Asegurarse de que los puertos **3000**, **3003** y **3004** estÃ©n disponibles.

---

## ğŸš€ Primer despliegue (Build Inicial)

Antes de iniciar por primera vez, es necesario construir las imÃ¡genes de Docker:

```bash
make build
make up
```

Esto crearÃ¡ las imÃ¡genes, restaurarÃ¡ la base de datos operativa y prepararÃ¡ el entorno completo para su ejecuciÃ³n.

---

## ğŸ”„ EjecuciÃ³n diaria (Reload de datos)

Para actualizar los datos diariamente, ejecuta el proceso ETL:

```bash
make all
```
---

## ğŸ“ˆ Proceso ETL

El proceso ETL realiza las siguientes acciones:

1. Espera que las bases de datos estÃ©n disponibles.
2. Elimina y recrea la base de datos **bi**.
3. Carga el esquema estrella desde `schema-bi.sql`.
4. Extrae, transforma y carga datos desde el ERP al DWH.
5. Crea la tabla de control `etl_ready`.

**Monitorizar proceso ETL**: `tail -f etl/etl.log`

---

## ğŸŒ Acceso a Metabase

Una vez iniciado el sistema, puedes acceder a la herramienta de visualizaciÃ³n:

- URL: [http://localhost:3000](http://localhost:3000)
- Usuario y contraseÃ±a: configurados en el archivo `.env`

La conexiÃ³n al DWH estÃ¡ preconfigurada para facilitar la creaciÃ³n de cuadros de mando y consultas.

[![Texto alternativo](img/ventas-sin-filtros.png)](img/ventas-sin-filtros.png)
---

## ğŸ“š Licencia

Proyecto desarrollado exclusivamente con fines educativos para el Trabajo Fin de Ciclo.

